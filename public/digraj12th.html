<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Imagire Lab. - member -</title>

    <!-- Bootstrap -->
  <link rel="stylesheet" type="text/css" href="../css/bootstrap.css">
  <style type="text/css">
  body { padding-top: 210px; }
  @media ( min-width: 768px ) {
    #banner {
      min-height: 300px;
      border-bottom: none;
    }
    .bs-docs-section {
      margin-top: 8em;
    }
    .bs-component {
      position: relative;
    }
    .bs-component .modal {
      position: relative;
      top: auto;
      right: auto;
      left: auto;
      bottom: auto;
      z-index: 1;
      display: block;
    }
    .bs-component .modal-dialog {
      width: 90%;
    }
    .bs-component .popover {
      position: relative;
      display: inline-block;
      width: 220px;
      margin: 20px;
    }
    .nav-tabs {
      margin-bottom: 15px;
    }
    .progress {
      margin-bottom: 10px;
    }
  }
footer {
  padding: 20px 0;
  color: #605060;
  background-color: #f0f0f0;
}
footer .github-star-button {
  margin-bottom: 1em;
}

  </style>

  <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="//oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
  </head>
  <body>

<header>
  <div class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <!-- .title: ヘッダのロゴ関連 -->
      <div class="title">
        <div class="row">
          <div class="col-md-8 clearfix">
          
            <h1><a href="//imagirelab.com/" class="logo">Imagire lab.</a></h1>
          
            <span class="description">東京工芸大学 芸術学部 ゲーム学科 今給黎 隆 研究室</span>
            <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
          </div>
        </div>
      </div>
      <!-- /.title -->
      <div class="navbar-collapse collapse" id="navbar-main">
        <ul class="nav navbar-nav">
          <li><a href="/">Top</a></li>
          <li><a href="/publications.html">Publications</a></li>
          <li><a href="/member.html">Member</a></li>
          <li><a href="/access.html">Access</a></li>
        </ul>
      </div>
    </div>
  </div>
</header>

<section class="section section-inverse japanese-font">
  <div class="container">
    <div class="row">
      <div class="col-xs-12 subtitle">
        <h2>トンボの視覚への実世界のリアルタイム変換</h2>
        <p>今給黎 隆 (東京工芸大学)</p>
        <p>日本デジタルゲーム学会 第12回年次大会 インタラクティブセッション</p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <h3>概要</h3>
        <p>本研究では、トンボが持つ色覚・広視野をリアルタイムにヘッドマウントディスプレイ(以下HMD)で再現をするシステムを提案する。360度カメラで撮影した動画をストリーミングによりHMDで表示する。HMDに表示する際に、複眼等のトンボの視覚特性を再現するようにリアルタイムに変換することであたかもトンボになったかのような世界を実現する。本研究は、HMDにおける視野拡張を実現するゲームの基礎研究であり、ITを用いた理科教育の一つの実践である。</p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-7">
        <h3>研究背景</h3>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-8">
        <p>VR FPSゲームで後ろの人を撃ちたいですよね。もしくは周り人と一度にコミュニケーションをとりたい時があるのではないでしょうか。
          これらを実現する分野は視野拡張になります。ただ、視野拡張はまだまだ定着しているとは言えないでしょう。
      </div>
      <div class="col-xs-4">
        <div class="embed-responsive embed-responsive-16by9">        
          <iframe src="https://www.youtube.com/embed/ym0vkhY6y-Q?autoplay=1&mute=1&playsinline=1&loop=1&playlist=ym0vkhY6y-Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
        <p class="text-center"> 
          HMDをかぶって後ろの人に手を振る人。
        </p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-8">
        <p>
          我々は、<a href="https://collab.t-kougei.ac.jp/2nd-exhibition/">「カラボギャラリー第2回企画展-色覚を考える展」</a>[1]
          や<a href="https://www.setagaya-ldc.net/program/516/">生活工房ギャラリー「色覚を考える展-ヒトと動物の色世界-」</a>[2]
          で、視野拡張の応用アプリケーションとしてトンボになって世界を覗き込むVR作品を展示してきました。
          これらの展示では、事前に用意した動画をヘッドマウントディスプレイ(HMD)の向きに応じてトンボの視覚に変換をしていました。
        </p><p>
          ただ、展示をしている中で気になることがありました。何人かの体験者はHMDの前で手を振っていたのです。
          様子を見ると、手を振って自分が入りこむのか試してみて、手が映らないことを確認すると、
          中の映像は現在の景色とは関係ないあらかじめ用意された動画なのだと認識しているようでした。
          このようなふるまいは何度か見られ、そこから来場者の期待は現在見ている物を他の視覚で見る事なのだなという思いに至りました。
        </p>
      </div>
      <div class="col-xs-4">
        <img src="digraj12th_exbi.jpg" class="img-responsive" alt="CHiKaフェスでのVR展示">
        <p class="text-center">
          CHiKaフェスでのVR展示
        </p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <h3>提案法</h3>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-xs-9">
        <p>
          今回、HMDとしてOculus Quest 2を使い、その上ににヘルメットストラップマウントで
          360度カメラのRICOH THETAを取り付けました。
          Oculus Quest 2は、Android OS で動いているので、HTTP通信で直接THETAと通信して、
          THETAの360度映像を直接取り込んで加工することは可能に思うのですが、
          試してもなかなか上手くいきませんでした
          (調べると、THETAのAPI実装の問題という記事が見つかるのですが現時点では原因は判明していません)。
        </p>
      </div>
      <div class="col-xs-3">
          <img src="digraj12th_HMD.jpg" class="img-responsive" alt="視野拡張システムHMD">
          <p>今回のシステムのHMD周辺。360度カメラはRICOH THETA V。</p>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-xs-8">
        <p>
          現時点では、外部にPCを用意して、外部PCからHTTP通信でTHETAの画像を取得しています。
          トンボの視覚への変換はOculus Quest 2でも可能ですが、PCからHMDに映像を送れる「Oculus Link」の機能が便利なので、
          Quest 2の情報を外部PCで受け取って映像のレンダリングを行った結果を、Oculus で表示しています。
        </p>
      </div>
      <div class="col-xs-4">
          <img src="digraj12th_system.png"  class="img-responsive" alt="視野拡張システム">
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <h3>実装: トンボの視覚</h3>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-xs-8">
        <p>
          トンボには単眼もあるものの、教育的な分かりやすさとして複眼を再現しています。
          また、複眼であることが分かりやすいように、あえて個眼の間を中央の位置ではっきりと分けています。
        </p>
        <p>
          トンボは2万個程度の個眼の集合である複眼を持っていることが知られていますが、それぞれの個眼では、特定の方向の光をとらえ、周囲を認識しています。
          今回は、複眼における個眼の配置を半球上の一様な点群の分布として再現しました（約1万個の点を半球上に等間隔に初期配置し、周囲の点との斥力を働かせる球面上のロイド緩和[3]のシミュレーションを用いて均等な間隔に配置しています）。
        </p>
      </div>
      <div class="col-xs-4">
          <img src="digraj12th_sampling.png"  class="img-responsive" alt="目のサンプリング点">
          <p>個眼の配置。片目だけ計算し、反対側の目は対称な位置に配置した。</p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <p>
          配置した個眼の位置情報はキューブマップに保存しました。
          キューブマップの各画素に最も近い個眼の減点からの向きを記録しています。
          キューブマップは、圧縮誤差を避けるためと符号付きフォーマットを使う理由から、実行時の最初に個眼の位置情報から作成しています。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-xs-12">
        <img src="digraj12th_XP.png" class="img-fluid" alt="X+">
        <img src="digraj12th_XN.png" class="img-fluid" alt="X-">
        <img src="digraj12th_YP.png" class="img-fluid" alt="Y+">
        <img src="digraj12th_YN.png" class="img-fluid" alt="Y-">
        <img src="digraj12th_ZP.png" class="img-fluid" alt="Z+">
        <img src="digraj12th_ZN.png" class="img-fluid" alt="Z-">
        <p>
          キューブマップの可視化。x, y, z成分を赤、緑、青で表示。
        </p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-8">
        <p>
          複眼による広範囲な視界を一度にとらえるため、視線方向を拡張しています。
          描画する画素の視点からの角度を3倍にして、上記個眼の位置情報のキューブマップや360度カメラからの画像を読み込んでいます。

        </p>
      </div>
      <div class="col-xs-4">
          <img src="digraj12th_view.png"  class="img-responsive" alt="視野拡張">
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <p>
          トンボの視覚の再現には、Futahashiら[4]の研究を応用しました。
          アキアカネ等は、背側の個眼と腹側の個眼で色覚が異なるため、個眼の向きの鉛直方向を見て、色覚を分けています。
          また、色を認識するオプシン遺伝子は複数の異なる種類を保持しています。
          今回は、個眼の向きに応じてランダムに反応する色を変えました。
        </p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <h3>結果</h3>
        <p>
          人間と視覚とトンボの視覚を切り替えながら歩いた映像です。
          制作したソフトウェアである Unity(2021.2.7f1) の画面をキャプチャーしました。
          360度カメラは、RICOH THETA Z1で、、Motion JPEGフォーマットの1920 x 960ライブビュー解像度のパノラマ画像を連続的に取得しています。
        </p>
        <p>
          人間と視覚とトンボの視覚を比較すると、トンボの方が一度に広い範囲が見えています。
          トンボは背側はほとんど影しか見えず（鳥などの捕食者が近づいてきた際に影となってすぐにわかるようにと言われています）、
          腹側は遠目で見るとそれらしい色（獲物を捕まえるために多彩な色が見えていると言われています）に見えるハニカム構造の視覚となります。
        </p>
        <p>
          <div class="embed-responsive embed-responsive-16by9">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/gQaTvdF6NM0?autoplay=1&mute=1&playsinline=1&loop=1&playlist=gQaTvdF6NM0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </p>
      </div>
    </div>
  </div>
    
<div class="container">
  <div class="row">
    <div class="col-xs-6">
      <img src="digraj12th_human.png" class="img-responsive" alt="人間の視覚での屋外">
      <p>
        人間の視覚での屋外。
      </p>
    </div>
    <div class="col-xs-6">
      <img src="digraj12th_dragonfly.png" class="img-responsive" alt="トンボの視覚での屋外">
      <p>
        左と同じ場所でのトンボの視覚の結果。
      </p>
    </div>
  </div>
</div>


  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <h3>今後の課題</h3>
        今回のものは、まだまだ良くできると思っています。
        <ul>
          <li>HMDや360度カメラの他に必要なPCをなくす</li>
          <li>Motion JPEGフォーマットの取り扱いが重ので高速化する</li>
          <li>トンボの色覚の再現なので、その後の脳の処理を踏まえた場合の最適な再現方法を検討</li>
          <li>個眼のレイアウトなど、実際のトンボの情報を用いた高品質化</li>
          <li>VR酔い対策</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <h3>謝辞</h3>
        <p>本研究は、「2021 年度コニカミノルタ科学技術振興財団研究奨励金」の助成を受けています。</p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <h3>参考文献</h3>
        <ol>
          <li>今給黎隆・大海悠太・野口靖(2018)「動物の色覚によるVR映像」, 色覚を考える展.</li>
          <li>「色覚を考える展-ヒトと動物の色世界-」, 生活工房ギャラリー, 2021 Sep. 24～2021 Oct. 29.</li>
          <li>Lloyd, Stuart P. (1982), "Least squares quantization in PCM", IEEE Transactions on Information Theory, 28 (2) , pp 129–137, doi:10.1109/TIT.1982.1056489.</li>
          <li>R. Futahashi, R. Kawahara-Miki, M. Kinoshita, K. Yoshitake, K. Yajima, K. Arikawa and T. Fukatsu (2015) "Extraordinary diversity of visual opsin genes in dragonflies", Proceedings of the National Academy of Sciences, 112(11), pp 1247–1256.</li>
        </ol>
      </div>
    </div>
  </div>



  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <h2>ファストフォワード動画</h2>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/V54uQuBnv24" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </div>
    </div>
  </div>
</section>

<footer class="small">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 text-center copyright">
                Copyright &copy; 2016 - Takashi Imagire.
            </div>
        </div>
    </div>
</footer>



    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="../js/bootstrap.min.js"></script>
  </body>
</html>
